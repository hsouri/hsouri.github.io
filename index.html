<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hossein Souri</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/jpg" href="Data/profile_face.png">
</head>


<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Hossein Souri</name>
                  </p>
                  <p>
                    
                    I am a PhD candidate in Computer Science at Johns Hopkins University, where I have the privilege of being supervised by 
                    Bloomberg Distinguished Professor <a href="https://engineering.jhu.edu/ece/faculty/rama-chellappa/"><b>Rama Chellappa</b></a>. 
                    My research is further enhanced by significant collaborations with 
                    Tom Goldstein, Micah Goldblum, and Soheil Feizi at the University of Maryland, as well as with Andrew Gordon Wilson and Yann LeCun from NYU and Meta.
                    
                    <p></p>
                    My research generally focuses on generative modeling, AI safety/security/fairness, multimodal modeling, transfer learning, and 2D computer vision. I have published multiple papers in top-tier 
                    conferences and journals, such as NeurIPS, ICLR, ICML, and TPAMI.
                    <p></p>
                    I'm a Graduate Reseach Assistant at Artificial Intelligence for Engineering and Medicine Lab (AIEM). 
                    Before joining JHU, I obtained my MS in Electrical and Computer Engineering from University of Maryland, College Park. 
                    During my Masters studies, I was a research assistant at University of Maryland Institute for Advanced Computer Studies (UMIACS).

                    <!-- I am PhD student in Computer Science at Johns Hopkins
                    University.
                    I'm pleased to be advised by <a
                      href="https://engineering.jhu.edu/ece/faculty/rama-chellappa/"><b>Prof. Rama Chellappa</b></a> and
                    <a href="https://www.cs.umd.edu/~tomg/"><b>Prof. Tom Goldstein</b></a>. I'm
                    a Graduate Reseach Assistant at Artificial Intelligence for
                    Engineering and Medicine Lab (<a href="https://aiem.jhu.edu/">AIEM</a>).
                  <p>
                    Before joining JHU, I obtained my M.S. and B.S. in Electrical and Computer Engineering from
                    University of Maryland, College Park and University of Tehran
                    respectively. During my Masters studies I was a reseach assistant at University of
                    Maryland Institute for Advanced Computer Studies (<a href="https://www.umiacs.umd.edu/">UMIACS</a>). -->

                  </p>
                  <p style="text-align:center">
                    <a href="mailto:hsouri1@jhu.edu">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=rurbhy0AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/hsouri">GitHub</a> &nbsp/&nbsp
                    <a href="https://twitter.com/HosseinSouri8">Twitter</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/hossein-souri-b7574795/">LinkedIn</a> &nbsp/&nbsp
                    <a href="Data/Hossein_Souri_CV.pdf">CV</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="Data/profile_circle_comp.png"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="Data/profile_circle_comp.png" class="hoverZoomLink"></a>
                </td>
              </tr>
          </table>



          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>News</heading>
                <!-- <br /> -->
                
                <ul>
                  <li><b>June-2024:</b> One paper accepted to ICML 2024 Workshop on the Next Generation of AI Safety. </li>
                </ul>

                <ul>
                  <li><b>Jan-2024:</b> One paper accepted to IEEE ICASSP 2024. </li>
                </ul>

                <ul>
                  <li><b>Sep-2023:</b> One paper accepted to NeurIPS 2023. </li>
                </ul>

                <ul>
                  <li><b>June-2023:</b> One paper accepted to TPAMI. </li>
                </ul>

                <ul>
                  <li><b>May-2023:</b> One papers accepted to AAAI/ACM Conference on AI, Ethics, and Society 2023. </li>
                </ul>

                <ul>

                  <li>
                    <b>Sep-2022:</b> Two papers accepted to NeurIPS
                    2022.
                  </li>
                </ul>

                <ul>
                  <li><b>July-2022:</b> Three papers accepted to ICML 2022 Workshops. </li>
                </ul>

                <ul>
                  <li><b>June-2022:</b> One paper accepted to IEEE TIFS. </li>
                  <!-- <a href="https://ieeexplore.ieee.org/abstract/document/9798870">Link</a>  -->
                </ul>

                <ul>
                  <li><b>Jan-2022:</b> One paper accepted to ICLR 2022. </li>
                  <!-- <a href="https://openreview.net/pdf?id=gICys3ITSmj">Link</a>  -->

                </ul>

                <ul>
                  <li><b>Nov-2020:</b> One <b>oral</b> paper accepted to IEEE FG 2020 with best paper (Honorable
                    Mention) award. </li>
                  <!-- <a href="https://ieeexplore.ieee.org/document/9320151">Link</a> -->
                </ul>


              </td>
            </tr>
          </table>





          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                    My primary research is applied machine learning and computer vision, focusing on improving the robustness,
                    transferability, and performance of image/face/video classifiers, object detection/segmentation, and generative
                    models. Those include adversarial robustness, transfer learning, self-supervised learning, diffusion models,
                    GANs, as well as, data poisoning and backdoor attacks.

                  </p>
                </td>
              </tr>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              

              <tr onmouseout="bob_stop()" onmouseover="bob_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bob_image'>
                      <img src='Data/GDP_1.jpg' width="160">
                    </div>
                    <img src='Data/GDP_2.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function bob_start() {
                      document.getElementById('bob_image').style.opacity = "0";
                    }

                    function bob_stop() {
                      document.getElementById('bob_image').style.opacity = "1";
                    }
                    bob_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2403.16365">
                    <papertitle> Generating Potent Poisons and Backdoors from Scratch with Guided Diffusion
                    </papertitle>
                  </a>
                  <br>
                  <strong>Hossein Souri</strong>, Arpit Bansal, Hamid Kazemi, Liam Fowl, Aniruddha Saha, Jonas Geiping, 
                  Andrew Gordon Wilson, Rama Chellappa, Tom Goldstein, Micah Goldblum
                  <br>
                  <em>ICML Workshop on the Next Generation of AI Safety</em>, 2024
                  <br>
                  <a href="https://arxiv.org/pdf/2403.16365.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2403.16365">arXiv</a> /
                  <a href="https://github.com/hsouri/GDP">code</a>
                  <br>
                  <p></p>
                  <p>
                    In this work, we use guided diffusion
                    to synthesize base samples from scratch that lead to significantly more potent
                    poisons and backdoors than previous state-of-the-art attacks. Our Guided Diffusion Poisoning (GDP) base samples can be combined with any downstream
                    poisoning or backdoor attack to boost its effectiveness.
                  </p>
                </td>
              </tr>

              
              <tr onmouseout="red_stop()" onmouseover="red_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='red_image'>
                      <img src='Data/red_before.png' width="160">
                    </div>
                    <img src='Data/red_after.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function red_start() {
                      document.getElementById('red_image').style.opacity = "0";
                    }

                    function red_stop() {
                      document.getElementById('red_image').style.opacity = "1";
                    }
                    red_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10446989">
                    <papertitle> Identifying Attack-Specific Signatures in Adversarial Examples
                    </papertitle>
                  </a>
                  <br>
                  <strong>Hossein Souri</strong>,
                  Pirazh Khorramshahi,
                  Chun Pong Lau,
                  Micah Goldblum,
                  Rama Chellappa
                  <br>
                  <em>IEEE ICASSP</em>, 2024
                  <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10446989 ">PDF</a> /
                  <a href="https://arxiv.org/abs/2110.06802">arXiv</a>
                  <!-- <a href="https://github.com/hsouri/Sleeper-Agent">code</a> -->
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    The adversarial attack literature contains a myriad of algorithms for
                    crafting perturbations which yield pathological behavior in neural networks.
                    In many cases, multiple algorithms target the same tasks and even enforce the
                    same constraints. In this work, we show that different attack algorithms produce
                    adversarial examples which are distinct not only in their effectiveness but also
                    in how they qualitatively affect their victims.</p>
                </td>
              </tr>



              <tr onmouseout="bob_stop()" onmouseover="bob_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bob_image'>
                      <img src='Data/bob.jpg' width="160">
                    </div>
                    <img src='Data/bob.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function bob_start() {
                      document.getElementById('bob_image').style.opacity = "0";
                    }

                    function bob_stop() {
                      document.getElementById('bob_image').style.opacity = "1";
                    }
                    bob_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2310.19909">
                    <papertitle> Battle of the Backbones: A Large-Scale Comparison of
                      Pretrained Models across Computer Vision Tasks
                    </papertitle>
                  </a>
                  <br>
                  Micah Goldblum*, <strong>Hossein Souri*</strong>, Renkun Ni, Manli Shu, Viraj Prabhu, 
                  Gowthami Somepalli, Prithvijit Chattopadhyay, Mark Ibrahim, Adrien Bardes, 
                  Judy Hoffman, Rama Chellappa, Andrew Gordon Wilson, Tom Goldstein
                  <br>
                  <font color="red"><strong><em>NeurIPS</em>, 2023</strong></font>
                  <br>
                  <a href="https://arxiv.org/pdf/2310.19909.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2310.19909">arXiv</a> /
                  <a href="https://github.com/hsouri/Battle-of-the-Backbones">code</a>
                  <br>
                  <p></p>
                  <p>
                  Battle of the Backbones (BoB) is a large-scale comparison of pretrained vision backbones 
                  including SSL, vision-language models, and CNNs vs ViTs across diverse downstream tasks 
                  including classification, object detection, segmentation, out-of-distribution (OOD) generalization, 
                  and image retrieval.
                  </p>
                </td>
              </tr>

              

              <tr onmouseout="ijsat_stop()" onmouseover="ijsat_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='ijsat_image'>
                      <img src='Data/ijsat_before.png' width="160">
                    </div>
                    <img src='Data/ijsat_after.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function ijsat_start() {
                      document.getElementById('ijsat_image').style.opacity = "0";
                    }

                    function ijsat_stop() {
                      document.getElementById('ijsat_image').style.opacity = "1";
                    }
                    ijsat_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/10155464/?casa_token=GHUaNLvLQeAAAAAA:IVLO-LH6zQoDTzAhBVQB4isDnu-MhvKtAXPyR3M_rVhsHr33rjru-p3syfWURrJrMABdL-nLjQ">
                    <papertitle> Interpolated Joint Space Adversarial Training for Robust and Generalizable Defenses
                    </papertitle>
                  </a>
                  <br>
                  Chun Pong Lau,
                  Jiang Liu,
                  <strong>Hossein Souri</strong>,
                  Wei-An Lin,
                  Soheil Feizi,
                  Rama Chellappa
                  <br>
                  <font color="red"><strong><em>TPAMI</em></strong></font>
                  <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/10155464/?casa_token=GHUaNLvLQeAAAAAA:IVLO-LH6zQoDTzAhBVQB4isDnu-MhvKtAXPyR3M_rVhsHr33rjru-p3syfWURrJrMABdL-nLjQ">PDF</a> /
                  <a href="https://arxiv.org/abs/2112.06323">arXiv</a> 
                  <!-- <a href="https://github.com/hsouri/Sleeper-Agent">code</a> -->
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    In this paper, we propose a novel threat model called
                    Joint Space Threat Model (JSTM), which can serve as a
                    special case of the neural perceptual threat model that does
                    not require additional relaxation to craft the corresponding adversarial attacks.
                    We also propose Intepolated Joint Space Adversarial Training
                    (IJSAT), which applies Robust Mixup strategy and trains
                    the model with JSA samples.
                  </p>
                </td>
              </tr>



              <tr onmouseout="deepdive_stop()" onmouseover="deepdive_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='deepdive_image'>
                      <img src='Data/deepdive_before.png' width="160">
                    </div>
                    <img src='Data/deepdive_after.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function deepdive_start() {
                      document.getElementById('deepdive_image').style.opacity = "0";
                    }

                    function deepdive_stop() {
                      document.getElementById('deepdive_image').style.opacity = "1";
                    }
                    deepdive_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.08235">
                    <papertitle> A Deep Dive into Dataset Imbalance and Bias in Face Identification
                    </papertitle>
                  </a>
                  <br>
                  Valeriia Cherepanova,
                  Steven Reich,
                  Samuel Dooley,
                  <strong>Hossein Souri</strong>,
                  Micah Goldblum,
                  Tom Goldstein
                  <br>
                  <em><strong>AIES</strong></em>, 2023
                  <br>
                  <a href="https://arxiv.org/pdf/2203.08235.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2203.08235">arXiv</a>
                  <!-- <a href="https://github.com/hsouri/Sleeper-Agent">code</a> -->
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    In this paper, we explore the effects of each kind of
                    imbalance possible in face identification, and discuss other factors which may impact bias in this
                    setting.</p>
                </td>
              </tr>


              <tr onmouseout="sleeper_stop()" onmouseover="sleeper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='sleep_image'>
                      <img src='Data/clean_source.png' width="160">
                    </div>
                    <img src='Data/patched_source.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function sleeper_start() {
                      document.getElementById('sleep_image').style.opacity = "0";
                    }

                    function sleeper_stop() {
                      document.getElementById('sleep_image').style.opacity = "1";
                    }
                    sleeper_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2106.08970">
                    <papertitle> Sleeper Agent: Scalable Hidden Trigger Backdoors for Neural Networks Trained from
                      Scratch</papertitle>
                  </a>
                  <br>
                  <strong>Hossein Souri</strong>,
                  Liam Fowl,
                  Rama Chellappa,
                  Micah Goldblum,
                  Tom Goldstein
                  <br>
                  <font color="red"><strong><em>NeurIPS</em>, 2022</strong></font>
                  <br>
                  <a href="https://arxiv.org/pdf/2106.08970.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2106.08970">arXiv</a> /
                  <a href="https://github.com/hsouri/Sleeper-Agent">code</a>
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    Typical backdoor attacks insert the trigger directly into the training data, although the presence
                    of such an attack may be visible upon inspection.
                    We develop a new hidden trigger attack, Sleeper Agent, which employs gradient matching, data
                    selection, and target model re-training during the crafting process.
                    Sleeper Agent is the first hidden trigger backdoor attack to be effective against neural networks
                    trained from scratch.
                    We demonstrate its effectiveness on ImageNet and in black-box settings.</p>
                </td>
              </tr>


              <tr onmouseout="prior_stop()" onmouseover="prior_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='prior_image'>
                      <img src='Data/prior_before.png' width="160">
                    </div>
                    <img src='Data/prior_after.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function prior_start() {
                      document.getElementById('prior_image').style.opacity = "0";
                    }

                    function prior_stop() {
                      document.getElementById('prior_image').style.opacity = "1";
                    }
                    prior_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2205.10279">
                    <papertitle> Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Priors
                    </papertitle>
                  </a>
                  <br>
                  Ravid Shwartz-Ziv,
                  Micah Goldblum,
                  <strong>Hossein Souri</strong>,
                  Sanyam Kapoor,
                  Chen Zhu,
                  Yann LeCun,
                  Andrew Gordon Wilson
                  <br>
                  <font color="red"><strong><em>NeurIPS</em>, 2022</strong></font>
                  <br>
                  <a href="https://arxiv.org/pdf/2205.10279.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2205.10279">arXiv</a> /
                  <a href="https://github.com/hsouri/BayesianTransferLearning">code</a>
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    Our Bayesian transfer learning framework transfers knowledge from pre-training
                    to downstream tasks. To up-weight parameter settings consistent with a
                    pre-training loss function, we fit a probability distribution over the
                    parameters of feature extractors to a pre-training loss function and rescale
                    it as a prior.</p>
                </td>
              </tr>





              <tr onmouseout="cmeta_stop()" onmouseover="cmeta_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='cmeta_image'>
                      <img src='Data/cmeta_before.png' width="160">
                    </div>
                    <img src='Data/cmeta_after.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cmeta_start() {
                      document.getElementById('cmeta_image').style.opacity = "0";
                    }

                    function cmeta_stop() {
                      document.getElementById('cmeta_image').style.opacity = "1";
                    }
                    cmeta_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://openreview.net/forum?id=gICys3ITSmj">
                    <papertitle> The Close Relationship Between Contrastive Learning and Meta-Learning
                    </papertitle>
                  </a>
                  <br>
                  Renkun Ni,
                  Manli Shu,
                  <strong>Hossein Souri</strong>,
                  Micah Goldblum,
                  Tom Goldstein
                  <br>
                  <font color="red"><strong><em>ICLR</em>, 2022</strong></font>
                  <br>
                  <a href="https://openreview.net/pdf?id=gICys3ITSmj">PDF</a> /
                  <a href="https://openreview.net/forum?id=gICys3ITSmj">arXiv</a> /
                  <a href="https://github.com/RenkunNi/MetaContrastive">code</a>
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    In this paper, we discuss the close relationship between contrastive learning and meta-learning
                    under a certain task distribution. We complement
                    this observation by showing that established meta-learning methods,
                    such as Prototypical Networks, achieve comparable performance to SimCLR
                    when paired with this task distribution.</p>
                </td>
              </tr>




              <tr onmouseout="mat_stop()" onmouseover="mat_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mat_image'>
                      <img src='Data/mat_before.png' width="160">
                    </div>
                    <img src='Data/mat_after.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function mat_start() {
                      document.getElementById('mat_image').style.opacity = "0";
                    }

                    function mat_stop() {
                      document.getElementById('mat_image').style.opacity = "1";
                    }
                    mat_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9798870">
                    <papertitle> Mutual Adversarial Training: Learning together is better than going alone
                    </papertitle>
                  </a>
                  <br>
                  Jiang Liu,
                  Chun Pong Lau,
                  <strong>Hossein Souri</strong>,
                  Soheil Feizi,
                  Rama Chellappa
                  <br>
                  <font color="red"><strong><em>IEEE TIFS</em>, 2022</strong></font>
                  <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/9798870">IEEE</a> /
                  <a href="https://arxiv.org/pdf/2112.05005.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2112.05005">arXiv</a>

                  <!-- <a href="https://github.com/hsouri/Sleeper-Agent">code</a> -->
                  <!--             <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>
                    In this paper, we propose mutual adversarial training (MAT), in which multiple models are trained
                    together and share the knowledge of adversarial examples to achieve improved robustness.
                    MAT allows robust models to explore a larger space of adversarial samples, and
                    find more robust feature spaces and decision boundaries.</p>
                </td>
              </tr>




              <tr onmouseout="mine_stop()" onmouseover="mine_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='mine_image'>
                      <img src='Data/62800.jpg' width="160">
                    </div>
                    <img src='Data/Vanilla_GAN_MNIST.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function mine_start() {
                      document.getElementById('mine_image').style.opacity = "1";
                    }

                    function mine_stop() {
                      document.getElementById('mine_image').style.opacity = "0";
                    }
                    bias_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2006.07845">
                    <papertitle> GANs with Variational Entropy Regularizers: Applications in Mitigating the
                      Mode-Collapse Issue</papertitle>
                  </a>
                  <br>
                  Pirazh Khorramshahi*,
                  <strong>Hossein Souri*</strong>,
                  Rama Chellappa,
                  Soheil Feizi
                  <br>
                  <em>arXiv</em>, 2020
                  <br>
                  <a href="https://arxiv.org/pdf/2009.11921.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2009.11921">arXiv</a>
                  <!-- <a
                    href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/khorramshahi2020gans.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>GANs often suffer from the mode collapse issue where the generator fails to capture all existing
                    modes of the input distribution.
                    To tackle this issue, we take an information-theoretic approach and maximize a variational lower
                    bound on the entropy of the generated samples to increase their diversity.
                    We call this approach GANs with Variational Entropy Regularizers (GAN+VER).</p>
                </td>
              </tr>





              <tr onmouseout="bias_stop()" onmouseover="bias_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bias_image'>
                      <img src='Data/bias_after.jpg' width="160">
                    </div>
                    <img src='Data/bias_before.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function bias_start() {
                      document.getElementById('bias_image').style.opacity = "1";
                    }

                    function bias_stop() {
                      document.getElementById('bias_image').style.opacity = "0";
                    }
                    bias_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2006.07845v1">
                    <papertitle> An adversarial learning algorithm for mitigating gender bias in face recognition
                    </papertitle>
                  </a>
                  <br>
                  Prithviraj Dhar,
                  Joshua Gleason,
                  <strong>Hossein Souri</strong>,
                  Carlos D. Castillo,
                  Rama Chellappa
                  <br>
                  <em>arXiv</em>, 2020
                  <br>
                  <a href="https://arxiv.org/pdf/2006.07845v1.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/2006.07845v1">arXiv</a>
                  <!-- <a
                    href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/dhar2020adversarial.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>A novel approach called "Adversarial Gender De-biasing (AGD)" to help
                    mitigate gender bias in face recognition by reducing
                    the strength of gender information in face recognition features.</p>
                  <br>
                  <font color="red"><strong>Updated Version</strong></font>
                  <br>
                  <a href="https://arxiv.org/abs/2006.07845v2">
                    <papertitle> Towards Gender-Neutral Face Descriptors for Mitigating Bias in Face Recognition
                    </papertitle>
                  </a>


                </td>
              </tr>




              <tr onmouseout="atface_stop()" onmouseover="atface_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='atface_image'>
                      <img src='Data/atface_after.png' width="160">
                    </div>
                    <img src='Data/atface_before.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function atface_start() {
                      document.getElementById('atface_image').style.opacity = "1";
                    }

                    function atface_stop() {
                      document.getElementById('atface_image').style.opacity = "0";
                    }
                    atface_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://ieeexplore.ieee.org/abstract/document/9320151">
                    <papertitle> ATFaceGAN: Single Face Image Restoration and Recognition from Atmospheric Turbulence
                    </papertitle>
                  </a>
                  <br>
                  Chun Pong Lau,
                  <strong>Hossein Souri</strong>,
                  Rama Chellappa
                  <br>
                  <em>FG</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
                  <br>
                  <a href="https://ieeexplore.ieee.org/abstract/document/9320151">IEEE</a> /
                  <a href="https://arxiv.org/pdf/1910.03119.pdf">PDF</a> /
                  <a href="https://arxiv.org/abs/1910.03119">arXiv</a>
                  <!-- <a href="https://github.com/hsouri/hsouri.github.io/blob/master/Data/lau2019atfacegan.bib">bibtex</a> -->
                  <br>
                  <p></p>
                  <p>In this work we propose a generative single frame restoration algorithm which disentangles the blur
                    and deformation due to turbulence and reconstructs a restored image.</p>
                </td>
              </tr>



              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                  <td width="100%" valign="middle">
                    <heading>Academic Service</heading>
                    <!-- <br /> -->
                    <ul>
                      <li>Conference Reviewer: CVPR, NeurIPS, ICLR, ICML, ECCV, ICCV, WACV</li>
                    </ul>
                    <ul>
                      <li>Journal Reviewer: Pattern Recognition Journal</li>
                    </ul>
                  </td>
                </tr>
              </table>


              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                  <td width="100%" valign="middle">
                    <heading>Research Experience</heading>
                    <!-- <br /> -->

                    <ul>
                      <li>Research Assistant, Johns Hopkins University, Aug 2020 - Present</li>
                    </ul>
                    <ul>
                      <li>Research Assistant, University of Maryland, 2018 - 2020</li>
                    </ul>
                    <ul>
                      <li>Research Assistant, University of Tehran, 2016 - 2018</li>
                    </ul>
                  </td>
                </tr>
              </table>


              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                  <td width="100%" valign="middle">
                    <heading>Teaching Experience</heading>
                    <!-- <br /> -->
                    <ul>
                      <li>Teaching Assistant, Machine Intelligence, Johns Hopkins University, Spring 2021, Spring 2022
                      </li>
                    </ul>
                    <ul>
                      <li>Teaching Assistant, Machine Perception, Johns Hopkins University, Fall 2021 </li>
                    </ul>
                    <ul>
                      <li>Teaching Assistant, University of Maryland, College Park, Fall 2018 - Spring 2019</li>
                    </ul>
                    <!-- <ul>
                <li>Teaching Assistant, University of Tehran, 2015 - 2018 </li>
              </ul> -->
                  </td>
                </tr>
              </table>


              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:center;font-size:small;">
                        <a href="https://jonbarron.info/">Source code</a>
                      </p>
                      <p style="text-align:center;font-size:small;">
                        Last update: July, 2024</p>

                      <!-- hitwebcounter Code START -->
                      <!-- Started from 1450-->
                      <!-- 2192 in May 2022-->
                      <!-- 2402 in July 2022-->
                      <!-- 2708 in Sep 2022-->
                      <!-- 2885 in Oct 2022-->
                      <!-- 2921 in Nov 2022-->

                      <!-- <a href="https://www.hitwebcounter.com" target="_blank">
                        <img
                          src="https://hitwebcounter.com/counter/counter.php?page=7892024&style=0006&nbdigits=9&type=page&initCount=1450"
                          title="Free Counter" Alt="web counter" border="0" /></a> -->

                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>